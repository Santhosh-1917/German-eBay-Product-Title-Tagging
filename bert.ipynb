{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d001c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ• Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "BASE_PATH = \"/Users/santhosh/Desktop/ebay\"\n",
    "TRAIN_FILE = f\"{BASE_PATH}/Tagged_Titles_Train.tsv\"\n",
    "LISTING_FILE = f\"{BASE_PATH}/Listing_Titles.tsv\"\n",
    "SUBMISSION_FILE = f\"{BASE_PATH}/submission_quiz.tsv\"\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"üñ• Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3f162dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_FILE, sep=\"\\t\", keep_default_na=False, na_values=None)\n",
    "df.columns = df.columns.str.strip().str.replace(\"Ôªø\",\"\", regex=True)\n",
    "df[\"Tag\"] = df[\"Tag\"].str.strip()\n",
    "df[\"Category\"] = df[\"Category\"].apply(lambda x: str(x).strip())\n",
    "\n",
    "# Replace empty tags with most frequent tag per category, else \"O\"\n",
    "most_freq_tag_by_cat = df[df[\"Tag\"] != \"\"].groupby(\"Category\")[\"Tag\"].agg(lambda x: x.value_counts().idxmax()).to_dict()\n",
    "df[\"Tag\"] = df.apply(lambda r: most_freq_tag_by_cat.get(r[\"Category\"], \"O\") if r[\"Tag\"] == \"\" else r[\"Tag\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf9f5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, texts, tags, tokenizer, tag2idx, max_len=64):\n",
    "        self.texts, self.tags = texts, tags\n",
    "        self.tokenizer, self.tag2idx = tokenizer, tag2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens, labels = self.texts[idx], self.tags[idx]\n",
    "        enc = self.tokenizer(tokens, is_split_into_words=True, truncation=True,\n",
    "                             padding=\"max_length\", max_length=self.max_len, return_tensors=\"pt\")\n",
    "        word_ids = enc.word_ids(0)\n",
    "        label_ids, prev_word = [], None\n",
    "        for w in word_ids:\n",
    "            if w is None:\n",
    "                label_ids.append(-100)\n",
    "            elif w != prev_word:\n",
    "                label_ids.append(self.tag2idx.get(labels[w], self.tag2idx[\"O\"]))\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            prev_word = w\n",
    "        enc = {k: v.squeeze() for k, v in enc.items()}\n",
    "        enc[\"labels\"] = torch.tensor(label_ids)\n",
    "        return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7138dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_category_model(category):\n",
    "    print(f\"\\n‚öôÔ∏è Training for Category {category}\")\n",
    "    cat_df = df[df[\"Category\"] == str(category)]\n",
    "\n",
    "    # Group by Record Number\n",
    "    records = []\n",
    "    for rec_id, g in cat_df.groupby(\"Record Number\"):\n",
    "        tokens = g[\"Token\"].tolist()\n",
    "        tags = g[\"Tag\"].tolist()\n",
    "        records.append((tokens, tags))\n",
    "\n",
    "    texts = [r[0] for r in records]\n",
    "    labels = [r[1] for r in records]\n",
    "\n",
    "    # Tag mappings\n",
    "    unique_tags = sorted(set(t for seq in labels for t in seq))\n",
    "    tag2idx = {t: i for i, t in enumerate(unique_tags)}\n",
    "    idx2tag = {i: t for t, i in tag2idx.items()}\n",
    "\n",
    "    # Split\n",
    "    split = int(0.8 * len(texts))\n",
    "    train_texts, val_texts = texts[:split], texts[split:]\n",
    "    train_tags, val_tags = labels[:split], labels[split:]\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-german-cased\")\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        \"distilbert-base-german-cased\",\n",
    "        num_labels=len(tag2idx),\n",
    "        id2label=idx2tag,\n",
    "        label2id=tag2idx\n",
    "    ).to(device)\n",
    "\n",
    "    train_loader = DataLoader(NERDataset(train_texts, train_tags, tokenizer, tag2idx), batch_size=8, shuffle=True)\n",
    "    val_loader = DataLoader(NERDataset(val_texts, val_tags, tokenizer, tag2idx), batch_size=8)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    epochs, patience = 20, 5\n",
    "    total_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps),\n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "    best_f1, patience_counter = 0, 0\n",
    "    save_dir = f\"{BASE_PATH}/models/Category_{category}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Category {category} | Epoch {epoch}/{epochs}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        preds, labels_all = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                logits = model(**batch).logits\n",
    "                pred = torch.argmax(logits, dim=-1)\n",
    "                for p, l, m in zip(pred.cpu(), batch[\"labels\"].cpu(), batch[\"attention_mask\"].cpu()):\n",
    "                    active = m == 1\n",
    "                    preds.extend(p[active].tolist())\n",
    "                    labels_all.extend(l[active].tolist())\n",
    "        f1 = f1_score(labels_all, preds, average=\"macro\")\n",
    "        print(f\"Epoch {epoch} | Loss: {avg_loss:.4f} | F1: {f1:.4f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"{save_dir}/best_model.pt\")\n",
    "            print(\"‚úÖ Model improved and saved.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(\"‚èπ Early stopping.\")\n",
    "                break\n",
    "\n",
    "    print(f\"üèÅ Finished Category {category} | Best F1: {best_f1:.4f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eb8f8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚öôÔ∏è Training for Category 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Category 1 | Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:30<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 1.5359 | F1: 0.3181\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:27<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.3532 | F1: 0.4754\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:29<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.2375 | F1: 0.5150\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:30<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.1806 | F1: 0.5302\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:21<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.1457 | F1: 0.5399\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:21<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 0.1203 | F1: 0.5619\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:21<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 0.0993 | F1: 0.5287\n",
      "No improvement. Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:21<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 0.0855 | F1: 0.5453\n",
      "No improvement. Patience: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:26<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 0.0728 | F1: 0.5520\n",
      "No improvement. Patience: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:26<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.0634 | F1: 0.5402\n",
      "No improvement. Patience: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 1 | Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:26<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Loss: 0.0524 | F1: 0.5168\n",
      "No improvement. Patience: 5/5\n",
      "‚èπ Early stopping.\n",
      "üèÅ Finished Category 1 | Best F1: 0.5619\n",
      "\n",
      "‚öôÔ∏è Training for Category 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Category 2 | Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:27<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 1.3721 | F1: 0.1672\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:23<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.2659 | F1: 0.2869\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:20<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.1703 | F1: 0.3323\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:21<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.1271 | F1: 0.3271\n",
      "No improvement. Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:27<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.0960 | F1: 0.3355\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:34<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 0.0797 | F1: 0.3235\n",
      "No improvement. Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:34<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 0.0598 | F1: 0.3640\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:49<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 0.0513 | F1: 0.3446\n",
      "No improvement. Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:36<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 0.0414 | F1: 0.3986\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:43<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.0327 | F1: 0.3895\n",
      "No improvement. Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:38<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Loss: 0.0293 | F1: 0.3996\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:30<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Loss: 0.0213 | F1: 0.3906\n",
      "No improvement. Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:29<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Loss: 0.0203 | F1: 0.3742\n",
      "No improvement. Patience: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:28<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Loss: 0.0152 | F1: 0.3798\n",
      "No improvement. Patience: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [02:10<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Loss: 0.0123 | F1: 0.4271\n",
      "‚úÖ Model improved and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:26<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Loss: 0.0109 | F1: 0.3937\n",
      "No improvement. Patience: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:29<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Loss: 0.0093 | F1: 0.3813\n",
      "No improvement. Patience: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:28<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Loss: 0.0079 | F1: 0.3821\n",
      "No improvement. Patience: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:28<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Loss: 0.0065 | F1: 0.3824\n",
      "No improvement. Patience: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Category 2 | Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:29<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 0.0057 | F1: 0.3805\n",
      "No improvement. Patience: 5/5\n",
      "‚èπ Early stopping.\n",
      "üèÅ Finished Category 2 | Best F1: 0.4271\n",
      "\n",
      "üéâ Training complete for both Category 1 and Category 2.\n"
     ]
    }
   ],
   "source": [
    "model_cat1 = train_category_model(1)\n",
    "model_cat2 = train_category_model(2)\n",
    "\n",
    "print(\"\\nüéâ Training complete for both Category 1 and Category 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39f9ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_category(category):\n",
    "    model_path = f\"{BASE_PATH}/models/Category_{category}/best_model.pt\"\n",
    "    model_name = \"distilbert-base-german-cased\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Load weights and detect label count\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    classifier_weight = [v for k, v in state_dict.items() if \"classifier.weight\" in k][0]\n",
    "    num_labels = classifier_weight.shape[0]\n",
    "\n",
    "    # Build model with correct label size\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    id2label = {i: f\"LABEL_{i}\" for i in range(num_labels)}  # generic fallback labels\n",
    "\n",
    "    subset = quiz_df[quiz_df[\"Category\"] == str(category)]\n",
    "    submission_rows = []\n",
    "\n",
    "    for _, row in tqdm(subset.iterrows(), total=len(subset), desc=f\"Predicting Category {category}\"):\n",
    "        tokens = row[\"Title\"].split()\n",
    "        enc = tokenizer(tokens, is_split_into_words=True, truncation=True,\n",
    "                        padding=\"max_length\", max_length=64, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(**enc).logits\n",
    "        preds = torch.argmax(logits, dim=2)[0].cpu().numpy()\n",
    "        word_ids = enc.word_ids(0)\n",
    "        seen = set()\n",
    "        for i, w_id in enumerate(word_ids):\n",
    "            if w_id is None or w_id in seen:\n",
    "                continue\n",
    "            seen.add(w_id)\n",
    "            tag = id2label.get(preds[i], \"O\")\n",
    "            token = tokens[w_id]\n",
    "            if tag != \"O\":\n",
    "                submission_rows.append([row[\"Record Number\"], row[\"Category\"], tag, token])\n",
    "    return submission_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bbf9813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Category 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12500/12500 [02:43<00:00, 76.27it/s]\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Predicting Category 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12500/12500 [02:38<00:00, 78.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Submission file created: /Users/santhosh/Desktop/ebay/submission_quiz.tsv\n",
      "Total predictions: 282349\n"
     ]
    }
   ],
   "source": [
    "rows_1 = predict_for_category(1)\n",
    "rows_2 = predict_for_category(2)\n",
    "\n",
    "# Combine and save\n",
    "final_rows = rows_1 + rows_2\n",
    "sub_df = pd.DataFrame(final_rows, columns=[\"Record Number\", \"Category\", \"Aspect Name\", \"Aspect Value\"])\n",
    "sub_df.to_csv(SUBMISSION_FILE, sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE, encoding=\"utf-8\")\n",
    "\n",
    "print(\"‚úÖ Submission file created:\", SUBMISSION_FILE)\n",
    "print(\"Total predictions:\", len(sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fe30302",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/santhosh/Desktop/ebay\"\n",
    "LISTING_FILE = f\"{BASE_PATH}/Listing_Titles.tsv\"\n",
    "SUBMISSION_FILE = f\"{BASE_PATH}/submission_quiz.tsv\"\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5601b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df = pd.read_csv(LISTING_FILE, sep=\"\\t\", keep_default_na=False, na_values=None)\n",
    "quiz_df[\"Category\"] = quiz_df[\"Category\"].astype(str)\n",
    "quiz_df = quiz_df[(quiz_df[\"Record Number\"] >= 5001) & (quiz_df[\"Record Number\"] <= 30000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3a761ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = sorted(set(t for seq in labels for t in seq))\n",
    "tag2idx = {t: i for i, t in enumerate(unique_tags)}\n",
    "idx2tag = {i: t for t, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88ce5741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All label mappings:\n",
      "0: Anwendung\n",
      "1: Anzahl_Der_Einheiten\n",
      "2: Besonderheiten\n",
      "3: Breite\n",
      "4: Bremsscheiben-Aussendurchmesser\n",
      "5: Bremsscheibenart\n",
      "6: Einbauposition\n",
      "7: Farbe\n",
      "8: Gr√∂√üe\n",
      "9: Hersteller\n",
      "10: Herstellernummer\n",
      "11: Herstellungsland_Und_-Region\n",
      "12: Im_Lieferumfang_Enthalten\n",
      "13: Kompatible_Fahrzeug_Marke\n",
      "14: Kompatibles_Fahrzeug_Jahr\n",
      "15: Kompatibles_Fahrzeug_Modell\n",
      "16: L√§nge\n",
      "17: Material\n",
      "18: Ma√üeinheit\n",
      "19: Menge\n",
      "20: Modell\n",
      "21: O\n",
      "22: Oberfl√§chenbeschaffenheit\n",
      "23: Oe/Oem_Referenznummer(N)\n",
      "24: Produktart\n",
      "25: Produktlinie\n",
      "26: SAE_Viskosit√§t\n",
      "27: St√§rke\n",
      "28: Technologie\n",
      "29: Z√§hnezahl\n"
     ]
    }
   ],
   "source": [
    "print(\"All label mappings:\")\n",
    "for i, tag in idx2tag.items():\n",
    "    print(f\"{i}: {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5d89365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All label values: ['Anwendung', 'Anzahl_Der_Einheiten', 'Besonderheiten', 'Breite', 'Bremsscheiben-Aussendurchmesser', 'Bremsscheibenart', 'Einbauposition', 'Farbe', 'Gr√∂√üe', 'Hersteller', 'Herstellernummer', 'Herstellungsland_Und_-Region', 'Im_Lieferumfang_Enthalten', 'Kompatible_Fahrzeug_Marke', 'Kompatibles_Fahrzeug_Jahr', 'Kompatibles_Fahrzeug_Modell', 'L√§nge', 'Material', 'Ma√üeinheit', 'Menge', 'Modell', 'O', 'Oberfl√§chenbeschaffenheit', 'Oe/Oem_Referenznummer(N)', 'Produktart', 'Produktlinie', 'SAE_Viskosit√§t', 'St√§rke', 'Technologie', 'Z√§hnezahl']\n"
     ]
    }
   ],
   "source": [
    "unique_tags = sorted(set(t for seq in labels for t in seq))\n",
    "tag2idx = {t: i for i, t in enumerate(unique_tags)}\n",
    "idx2tag = {i: t for t, i in tag2idx.items()}\n",
    "\n",
    "# Save all labels as a simple array\n",
    "label_list = [idx2tag[i] for i in range(len(idx2tag))]\n",
    "print(\"All label values:\", label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0801af12",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: EOF inside string starting at row 200449",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m SUBMISSION_FILE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/submission_quiz.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the current submission file\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSUBMISSION_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ==============================================================\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load label mappings from each category\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# ==============================================================\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Category 1\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/models/Category_1/idx2tag.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/parsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: EOF inside string starting at row 200449"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "BASE_PATH = \"/Users/santhosh/Desktop/ebay\"\n",
    "SUBMISSION_FILE = f\"{BASE_PATH}/submission_quiz.tsv\"\n",
    "\n",
    "# Load the current submission file\n",
    "df = pd.read_csv(SUBMISSION_FILE, sep=\"\\t\")\n",
    "\n",
    "# ==============================================================\n",
    "# Load label mappings from each category\n",
    "# ==============================================================\n",
    "\n",
    "# Category 1\n",
    "with open(f\"{BASE_PATH}/models/Category_1/idx2tag.json\", \"r\") as f:\n",
    "    idx2tag_1 = json.load(f)\n",
    "idx2tag_1 = {f\"LABEL_{k}\": v for k, v in idx2tag_1.items()}\n",
    "\n",
    "# Category 2\n",
    "with open(f\"{BASE_PATH}/models/Category_2/idx2tag.json\", \"r\") as f:\n",
    "    idx2tag_2 = json.load(f)\n",
    "idx2tag_2 = {f\"LABEL_{k}\": v for k, v in idx2tag_2.items()}\n",
    "\n",
    "# ==============================================================\n",
    "# Replace label names in Aspect Name column\n",
    "# ==============================================================\n",
    "\n",
    "def map_label(row):\n",
    "    label = row[\"Aspect Name\"]\n",
    "    cat = str(row[\"Category\"])\n",
    "    if cat == \"1\" and label in idx2tag_1:\n",
    "        return idx2tag_1[label]\n",
    "    elif cat == \"2\" and label in idx2tag_2:\n",
    "        return idx2tag_2[label]\n",
    "    else:\n",
    "        return label  # keep unchanged if not found\n",
    "\n",
    "df[\"Aspect Name\"] = df.apply(map_label, axis=1)\n",
    "\n",
    "# ==============================================================\n",
    "# Save the cleaned submission\n",
    "# ==============================================================\n",
    "\n",
    "output_file = f\"{BASE_PATH}/submission_quiz_clean.tsv\"\n",
    "df.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"‚úÖ Cleaned submission created:\", output_file)\n",
    "print(\"Sample preview:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a840682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    SUBMISSION_FILE,\n",
    "    sep=\"\\t\",\n",
    "    engine=\"python\",          # more forgiving parser\n",
    "    quoting=3,                # quotechar=None equivalent\n",
    "    on_bad_lines=\"skip\",      # skip broken lines instead of dying\n",
    "    encoding=\"utf-8\",\n",
    "    dtype=str                 # avoid type inference confusion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "794186c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows loaded: 282349\n",
      "  Record Number Category Aspect Name Aspect Value\n",
      "0          5001        1    LABEL_11         OPEL\n",
      "1          5001        1    LABEL_13        ASTRA\n",
      "2          5001        1    LABEL_17            H\n",
      "3          5001        1    LABEL_17          1.7\n",
      "4          5001        1    LABEL_17     CDTI-SET\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows loaded:\", len(df))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47ced815",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Anwendung' is not a valid function for 'Series' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAspect Name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/frame.py:10401\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10387\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10389\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10391\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10399\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10400\u001b[0m )\n\u001b[0;32m> 10401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    871\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumba\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m engine doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support lists of callables yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         )\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_list_or_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# all empty\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:622\u001b[0m, in \u001b[0;36mApply.apply_list_or_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumba\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m engine doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support list-like/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict likes of callables yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    619\u001b[0m     )\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, ABCDataFrame):\n\u001b[0;32m--> 622\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    624\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    625\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/frame.py:10401\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10387\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10389\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10390\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10391\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10399\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10400\u001b[0m )\n\u001b[0;32m> 10401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumba\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    871\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumba\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m engine doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support lists of callables yet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         )\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_list_or_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# all empty\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:630\u001b[0m, in \u001b[0;36mApply.apply_list_or_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_dict_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapply\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m result \u001b[38;5;241m=\u001b[39m reconstruct_and_relabel_result(result, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:744\u001b[0m, in \u001b[0;36mNDFrameApply.agg_or_apply_list_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis other than 0 is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 744\u001b[0m keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:385\u001b[0m, in \u001b[0;36mApply.compute_list_like\u001b[0;34m(self, op_name, selected_obj, kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(col, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj\u001b[38;5;241m.\u001b[39miloc[:, index])\n\u001b[1;32m    380\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    381\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    384\u001b[0m )\n\u001b[0;32m--> 385\u001b[0m new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[1;32m    387\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend(index)\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/series.py:4936\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4809\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4810\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4816\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4817\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4934\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4937\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4941\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:1412\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;66;03m# dispatch to handle list-like or dict-like\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m-> 1412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_list_or_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:630\u001b[0m, in \u001b[0;36mApply.apply_list_or_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_dict_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapply\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m result \u001b[38;5;241m=\u001b[39m reconstruct_and_relabel_result(result, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:744\u001b[0m, in \u001b[0;36mNDFrameApply.agg_or_apply_list_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis other than 0 is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 744\u001b[0m keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_list_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:369\u001b[0m, in \u001b[0;36mApply.compute_list_like\u001b[0;34m(self, op_name, selected_obj, kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(selected_obj\u001b[38;5;241m.\u001b[39mname, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj)\n\u001b[1;32m    364\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    365\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    368\u001b[0m )\n\u001b[0;32m--> 369\u001b[0m new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# make sure we find a good name\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/series.py:4936\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4809\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4810\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4816\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4817\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4934\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4937\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4941\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:1416\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_list_or_dict_like()\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m-> 1416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mby_row \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_compat\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:603\u001b[0m, in \u001b[0;36mApply.apply_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis\n\u001b[0;32m--> 603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/eBay/.venv-1/lib/python3.9/site-packages/pandas/core/apply.py:706\u001b[0m, in \u001b[0;36mApply._apply_str\u001b[0;34m(self, obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a valid function for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Anwendung' is not a valid function for 'Series' object"
     ]
    }
   ],
   "source": [
    "df[\"Aspect Name\"] = df.apply(label_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a294504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anwendung',\n",
       " 'Anzahl_Der_Einheiten',\n",
       " 'Besonderheiten',\n",
       " 'Breite',\n",
       " 'Bremsscheiben-Aussendurchmesser',\n",
       " 'Bremsscheibenart',\n",
       " 'Einbauposition',\n",
       " 'Farbe',\n",
       " 'Gr√∂√üe',\n",
       " 'Hersteller',\n",
       " 'Herstellernummer',\n",
       " 'Herstellungsland_Und_-Region',\n",
       " 'Im_Lieferumfang_Enthalten',\n",
       " 'Kompatible_Fahrzeug_Marke',\n",
       " 'Kompatibles_Fahrzeug_Jahr',\n",
       " 'Kompatibles_Fahrzeug_Modell',\n",
       " 'L√§nge',\n",
       " 'Material',\n",
       " 'Ma√üeinheit',\n",
       " 'Menge',\n",
       " 'Modell',\n",
       " 'O',\n",
       " 'Oberfl√§chenbeschaffenheit',\n",
       " 'Oe/Oem_Referenznummer(N)',\n",
       " 'Produktart',\n",
       " 'Produktlinie',\n",
       " 'SAE_Viskosit√§t',\n",
       " 'St√§rke',\n",
       " 'Technologie',\n",
       " 'Z√§hnezahl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b174f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-1 (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
